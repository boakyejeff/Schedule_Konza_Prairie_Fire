{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized Data Baseline ML Tests\n",
    "\n",
    "Required Data File `./normalized_global_bands_mean_stdev.csv.csv`\n",
    "\n",
    "\n",
    "## Basic Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset location\n",
    "DATASET = 'normalized_global_bands_mean_stdev.csv'\n",
    "assert os.path.exists(DATASET)\n",
    "\n",
    "# Load and shuffle\n",
    "dataset = pd.read_csv(DATASET).sample(frac = 1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Becaues we are using `sample(frac = 1)` we are randomizing all the data. Therefore, results will vary from time to time based on the data set reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>isBurnt</th>\n",
       "      <th>YrMo</th>\n",
       "      <th>mean_B1</th>\n",
       "      <th>stdev_B1</th>\n",
       "      <th>mean_B2</th>\n",
       "      <th>stdev_B2</th>\n",
       "      <th>mean_B3</th>\n",
       "      <th>stdev_B3</th>\n",
       "      <th>mean_B4</th>\n",
       "      <th>stdev_B4</th>\n",
       "      <th>mean_B5</th>\n",
       "      <th>stdev_B5</th>\n",
       "      <th>mean_B6</th>\n",
       "      <th>stdev_B6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96633</td>\n",
       "      <td>1895</td>\n",
       "      <td>1</td>\n",
       "      <td>2006_4</td>\n",
       "      <td>0.289871</td>\n",
       "      <td>0.018321</td>\n",
       "      <td>0.325234</td>\n",
       "      <td>0.022417</td>\n",
       "      <td>0.333848</td>\n",
       "      <td>0.035823</td>\n",
       "      <td>0.465070</td>\n",
       "      <td>0.015978</td>\n",
       "      <td>0.551544</td>\n",
       "      <td>0.069900</td>\n",
       "      <td>0.426185</td>\n",
       "      <td>0.058404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66228</td>\n",
       "      <td>1299</td>\n",
       "      <td>1</td>\n",
       "      <td>2000_6</td>\n",
       "      <td>0.294635</td>\n",
       "      <td>0.014078</td>\n",
       "      <td>0.311422</td>\n",
       "      <td>0.026444</td>\n",
       "      <td>0.347196</td>\n",
       "      <td>0.039621</td>\n",
       "      <td>0.420551</td>\n",
       "      <td>0.048489</td>\n",
       "      <td>0.529021</td>\n",
       "      <td>0.062735</td>\n",
       "      <td>0.429769</td>\n",
       "      <td>0.042028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132256</td>\n",
       "      <td>2594</td>\n",
       "      <td>1</td>\n",
       "      <td>1991_4</td>\n",
       "      <td>0.317965</td>\n",
       "      <td>0.013440</td>\n",
       "      <td>0.357450</td>\n",
       "      <td>0.018805</td>\n",
       "      <td>0.396201</td>\n",
       "      <td>0.019195</td>\n",
       "      <td>0.479060</td>\n",
       "      <td>0.029404</td>\n",
       "      <td>0.598714</td>\n",
       "      <td>0.042791</td>\n",
       "      <td>0.476667</td>\n",
       "      <td>0.041141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23069</td>\n",
       "      <td>453</td>\n",
       "      <td>1</td>\n",
       "      <td>1993_8</td>\n",
       "      <td>0.271130</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>0.306024</td>\n",
       "      <td>0.008943</td>\n",
       "      <td>0.300415</td>\n",
       "      <td>0.010947</td>\n",
       "      <td>0.498327</td>\n",
       "      <td>0.033548</td>\n",
       "      <td>0.488716</td>\n",
       "      <td>0.026404</td>\n",
       "      <td>0.378257</td>\n",
       "      <td>0.024147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120014</td>\n",
       "      <td>2354</td>\n",
       "      <td>1</td>\n",
       "      <td>1990_5</td>\n",
       "      <td>0.239587</td>\n",
       "      <td>0.277020</td>\n",
       "      <td>0.264273</td>\n",
       "      <td>0.314793</td>\n",
       "      <td>0.274977</td>\n",
       "      <td>0.325804</td>\n",
       "      <td>0.354925</td>\n",
       "      <td>0.410307</td>\n",
       "      <td>0.375528</td>\n",
       "      <td>0.435451</td>\n",
       "      <td>0.306269</td>\n",
       "      <td>0.371245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  OBJECTID  isBurnt    YrMo   mean_B1  stdev_B1   mean_B2  \\\n",
       "0       96633      1895        1  2006_4  0.289871  0.018321  0.325234   \n",
       "1       66228      1299        1  2000_6  0.294635  0.014078  0.311422   \n",
       "2      132256      2594        1  1991_4  0.317965  0.013440  0.357450   \n",
       "3       23069       453        1  1993_8  0.271130  0.006706  0.306024   \n",
       "4      120014      2354        1  1990_5  0.239587  0.277020  0.264273   \n",
       "\n",
       "   stdev_B2   mean_B3  stdev_B3   mean_B4  stdev_B4   mean_B5  stdev_B5  \\\n",
       "0  0.022417  0.333848  0.035823  0.465070  0.015978  0.551544  0.069900   \n",
       "1  0.026444  0.347196  0.039621  0.420551  0.048489  0.529021  0.062735   \n",
       "2  0.018805  0.396201  0.019195  0.479060  0.029404  0.598714  0.042791   \n",
       "3  0.008943  0.300415  0.010947  0.498327  0.033548  0.488716  0.026404   \n",
       "4  0.314793  0.274977  0.325804  0.354925  0.410307  0.375528  0.435451   \n",
       "\n",
       "    mean_B6  stdev_B6  \n",
       "0  0.426185  0.058404  \n",
       "1  0.429769  0.042028  \n",
       "2  0.476667  0.041141  \n",
       "3  0.378257  0.024147  \n",
       "4  0.306269  0.371245  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop first 3 columns and isBurnt label\n",
    "# 0 index of columns - so \",4\" drops  {0,1,2,3}\n",
    "X = np.array(dataset.iloc[:,4:])\n",
    "y = np.array(dataset.isBurnt)\n",
    "y = y - 1  #shift from {1.2} to {0,1} for non-burn, burn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test Baseline ML Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline a resubstitution Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.89320\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of a model that can be trained\n",
    "model = LogisticRegression()\n",
    "\n",
    "# fit = \"train model parameters using this data and expected outcomes\"\n",
    "model.fit(X, y)       \n",
    "LR_RESUB_SCORE = model.score(X, y)\n",
    "print(\"Logistic Regression: {0:6.5f}\".format(LR_RESUB_SCORE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Baseline a resubstitution KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN : 0.93273\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of a model that can be trained\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "# fit = \"train model parameters using this data and expected outcomes\"\n",
    "model.fit(X, y)   \n",
    "KNN_RESUB_SCORE = model.score(X, y)\n",
    "print(\"KNN : {0:6.5f}\".format(KNN_RESUB_SCORE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Baseline a resubstitution Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: 0.99982\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of a model that can be trained\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# fit = \"train model parameters using this data and expected outcomes\"\n",
    "model.fit(X, y)       \n",
    "DT_RESUB_SCORE = model.score(X, y)\n",
    "print(\"Decision Tree: {0:6.5f}\".format(DT_RESUB_SCORE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Baseline a resubstitution LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC Regression: 0.89324\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of a model that can be trained\n",
    "model = LinearSVC()\n",
    "\n",
    "# fit = \"train model parameters using this data and expected outcomes\"\n",
    "model.fit(X, y)       \n",
    "SVC_RESUB_SCORE = model.score(X, y)\n",
    "print(\"Linear SVC Regression: {0:6.5f}\".format(SVC_RESUB_SCORE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Resubstitution Model Summary\n",
    "\n",
    "* Logistic Regression: 0.89320\n",
    "* K(5) Nearest Neighbors: 0.93273\n",
    "* Decision Tree: 0.99982\n",
    "* Linear SVC: 0.89324\n",
    "\n",
    "### Question: How to these resubstitution scores differ from unnormalized?  (5 pts)\n",
    "### Thoughts on why? (5 pts)\n",
    "\n",
    "---\n",
    "\n",
    "## Cross-Fold Analysis of Classifier Generalizability\n",
    "We are going to do a 5-fold cross validation for each model.\n",
    "Then, compare the degrade."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "How to these resubstitution scores differ from unnormalized? (5 pts)\n",
    "Compared to the unnormalized data, the resubstitution scores for Logistic Regression (0.89320 vs. 0.89292) and Linear SVC (0.89324 vs. 0.89322) remain almost identical, showing minimal improvement. However, the K-Nearest Neighbors (0.93273 vs. 0.93350) score slightly decreased, and the Decision Tree (0.99982 in both cases) remains unchanged."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Thoughts on why? (5 pts)\n",
    "I think normalization standardizes the data to a consistent scale (0 to 1), which typically benefits distance-based models like KNN and SVM by improving numerical stability and convergence. However, in this case, the results suggest that the original data was already well-scaled, leading to minimal changes for Logistic Regression and SVC. The slight drop in KNNâ€™s performance could be due to subtle shifts in feature distances after normalization. Meanwhile, Decision Trees are inherently insensitive to scaling since they split data based on feature thresholds rather than distance calculations, explaining why its score remains the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "XFOLD = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resub Logistic Regression: 0.89320\n",
      "Fold 0: 0.89326, change  0.01%\n",
      "Fold 1: 0.89322, change  0.00%\n",
      "Fold 2: 0.89310, change -0.01%\n",
      "Fold 3: 0.89314, change -0.01%\n",
      "Fold 4: 0.89318, change -0.00%\n",
      "Average Logit Acc 89.32%\n"
     ]
    }
   ],
   "source": [
    "# Hide the pesky warnings from Logit\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "# new model\n",
    "model = LogisticRegression()\n",
    "# Show Prior\n",
    "print(\"Resub Logistic Regression: {0:6.5f}\".format(LR_RESUB_SCORE))\n",
    "# Run Cross Val\n",
    "cv_results = sklearn.model_selection.cross_val_score(model, X, y, cv=XFOLD)\n",
    "\n",
    "for i,acc in enumerate(cv_results):\n",
    "    change = (acc-LR_RESUB_SCORE)/LR_RESUB_SCORE * 100\n",
    "    print(\"Fold {}: {:6.5f}, change {:5.2f}%\".format(i,acc,change))\n",
    "\n",
    "print(\"Average Logit Acc {:5.2f}%\".format(np.mean(cv_results)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resub KNN: 0.93273\n",
      "Fold 0: 0.90667, change -2.79%\n",
      "Fold 1: 0.90693, change -2.77%\n",
      "Fold 2: 0.90637, change -2.83%\n",
      "Fold 3: 0.90693, change -2.77%\n",
      "Fold 4: 0.90811, change -2.64%\n",
      "Average KNN Acc 90.70%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# new model\n",
    "model = KNeighborsClassifier()\n",
    "# Show Prior\n",
    "print(\"Resub KNN: {0:6.5f}\".format(KNN_RESUB_SCORE))\n",
    "# Run Cross Val\n",
    "cv_results = sklearn.model_selection.cross_val_score(model, X, y, cv=XFOLD)\n",
    "\n",
    "for i,acc in enumerate(cv_results):\n",
    "    change = (acc-KNN_RESUB_SCORE)/KNN_RESUB_SCORE * 100\n",
    "    print(\"Fold {}: {:6.5f}, change {:5.2f}%\".format(i,acc,change))\n",
    "    \n",
    "print(\"Average KNN Acc {:5.2f}%\".format(np.mean(cv_results)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resub Decision Tree: 0.99982\n",
      "Fold 0: 0.87017, change -12.97%\n",
      "Fold 1: 0.87102, change -12.88%\n",
      "Fold 2: 0.86813, change -13.17%\n",
      "Fold 3: 0.86498, change -13.49%\n",
      "Fold 4: 0.86506, change -13.48%\n",
      "Average Decision Tree Acc 86.79%\n"
     ]
    }
   ],
   "source": [
    "# new model\n",
    "model = DecisionTreeClassifier()\n",
    "# Show Prior\n",
    "print(\"Resub Decision Tree: {0:6.5f}\".format(DT_RESUB_SCORE))\n",
    "# Run Cross Val\n",
    "cv_results = sklearn.model_selection.cross_val_score(model, X, y, cv=XFOLD)\n",
    "\n",
    "for i,acc in enumerate(cv_results):\n",
    "    change = (acc-DT_RESUB_SCORE)/DT_RESUB_SCORE * 100\n",
    "    print(\"Fold {}: {:6.5f}, change {:5.2f}%\".format(i,acc,change))\n",
    "    \n",
    "print(\"Average Decision Tree Acc {:5.2f}%\".format(np.mean(cv_results)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resub SVC: 0.89324\n",
      "Fold 0: 0.89329, change  0.01%\n",
      "Fold 1: 0.89325, change  0.00%\n",
      "Fold 2: 0.89322, change -0.00%\n",
      "Fold 3: 0.89325, change  0.00%\n",
      "Fold 4: 0.89314, change -0.01%\n",
      "Average Linear SVC Acc 89.32%\n"
     ]
    }
   ],
   "source": [
    "# new model\n",
    "model = LinearSVC()\n",
    "# Show Prior\n",
    "print(\"Resub SVC: {0:6.5f}\".format(SVC_RESUB_SCORE))\n",
    "# Run Cross Val\n",
    "cv_results = sklearn.model_selection.cross_val_score(model, X, y, cv=XFOLD)\n",
    "\n",
    "for i,acc in enumerate(cv_results):\n",
    "    change = (acc-SVC_RESUB_SCORE)/SVC_RESUB_SCORE * 100\n",
    "    print(\"Fold {}: {:6.5f}, change {:5.2f}%\".format(i,acc,change))\n",
    "    \n",
    "print(\"Average Linear SVC Acc {:5.2f}%\".format(np.mean(cv_results)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes \n",
    " * Average Logist Reg Acc 89.32%\n",
    " * Average KNN Acc 90.60%\n",
    " * Average Decision Tree Acc 86.72%\n",
    " * Average Linear SVC Acc 89.32%\n",
    "\n",
    "## Questions:  \n",
    "### Based on the numbers above, which method seems to be overfitting the worst? (2 pts)\n",
    "\n",
    "### How can you tell if it is overfitting? (2 pts)\n",
    "\n",
    "### Which is the most consistent with the normalized data? (2 pts)\n",
    "\n",
    "### Which is the best model and what is it's accuracy? (2 pts)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Which method seems to be overfitting the worst? (2 pts)\n",
    "The Decision Tree Classifier is overfitting the worst. It has a resubstitution accuracy of 99.98%, but its cross-validation accuracy drops significantly to 86.79%, indicating that it performs exceptionally well on the training data but poorly on unseen data."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "How can you tell if it is overfitting? (2 pts)\n",
    "Overfitting is evident when there is a large gap between resubstitution accuracy (training performance) and cross-validation accuracy (performance on unseen data). The Decision Tree shows a drop of over 13%, which is much larger than other models, confirming severe overfitting."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Which is the most consistent with the normalized data? (2 pts)\n",
    "The Logistic Regression and Linear SVC models are the most consistent with the normalized data, both showing an average accuracy of 89.32% with minimal fluctuations across cross-validation folds."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Which is the best model and what is its accuracy? (2 pts)\n",
    "The K-Nearest Neighbors (KNN) model is the best model, achieving the highest cross-validation accuracy of 90.70%, making it the most generalizable and effective model for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take best classifer, do train/test split and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of a model that can be trained\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# This function returns four sets:\n",
    "# Training features\n",
    "#       # Testing features\n",
    "#       #        # Training labels\n",
    "#       #        #        # Testing labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                                    test_size=0.20)\n",
    "\n",
    "# fit = \"train model parameters using this data and expected outcomes\"\n",
    "model.fit(X_train, y_train)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "# Function borrowed from:\n",
    "# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)\n",
    "#pred_class = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[0.97 0.03]\n",
      " [0.65 0.35]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAELCAYAAADkyZC4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZyVZf3/8dd7BmURAhQlEETcUisV9Ktpi6bmUm6VmpqZaZqWZpqm5pLZYppbLi2aW+ba4i9yiVIzl9Qg9yUNV1BRQCRAQYHP74/rGjiMs5zBc8+Ze+b95HEenHNv53NmzpzPua7PdV+3IgIzM7Naa6h3AGZm1j05wZiZWSGcYMzMrBBOMGZmVggnGDMzK4QTjJmZFaJXvQMwM7OOaXzfqIgFb3Von3hr2viI2KGgkFrkBGNmVjKxYB69192rQ/vMe/D8IQWF0yonGDOzshEg1TuKdjnBmJmVkbp+Cd0JxsysjNyCMTOz2pNbMGZmVhC3YMzMrOaEWzBmZlYEuQVjZmYFcQvGzMwK4RaMmZnVnkeRmZlZEXwmv5mZFcYtGDMzqz13kZmZWREENDbWO4p2OcGYmZWRazBmZlZ77iIzM7OiuAVjZmaFcAvGzMxqTp6LzMzMiuIWjJmZFcItGDMzqz2PIjMzs6K4BWNmZjXnK1qamVkx3EVmZmZFcReZmZkVwi0YMzMrhFswZmZWc3INxszMiuIWjJmZFUFOMGZmVmvCCcbMzIqgfOvinGDMzEpHbsGYmVkxnGDMzKwQTjBmZlaIMiSYrn+mjvVYkk6R9Nt8fzVJcyQ11vg5npe0bS2PWcVzHirp1fx6VnoPx5kjaY1axlYvkh6XtFW94ygNLcOtDtyC6cEkPQ/0A0ZHxNy87KvAvhGxVR1De5eIeBHoX+843itJywFnAx+JiIffy7Eiosv/PCRdDkyJiBPb2i4iPtg5EXUPKkmR3y0YawSOeK8HUeL3U/uGAn2Ax+sdSFcgyV9yl1FDQ0OHbu2RtIOkpyRNknRcC+tXk/R3SQ9KekTSp9uNcRlfm3UfPwWOljSopZWStpA0QdKs/P8WFevukPQjSfcAbwJr5GU/lPTP3IXzZ0krSbpK0v/yMVavOMbPJE3O6/4t6eOtxLG6pJDUS9Lm+dhNt3m5NYakBknHSXpG0gxJ10taseI4X5L0Ql53Qls/GEl9JZ2Vt58l6W5JffO6XXK3zhv5Na9Xsd/zko7Of4SzJF0nqY+kdYCn8mZvSLq98nU1+7l+Nd9fS9I/8nGmS7quYruQtFa+P1DSbyRNy/Ge2JTwJe2fYz9T0kxJz0nasY3X/bykY3L8cyVdImmopFskzZZ0q6TBFdv/TtLUHOOdkj6Ylx8MfBH4TtN7oeL4x0p6BJibf6eLuyol3SzprIrjXyvp0rZ+Vz2RpA7d2jlWI3AhsCOwPrC3pPWbbXYicH1EjAH2An7eXoxOMDYRuAM4uvmK/MF8E3AesBKpa+cmLV03+BJwMDAAeCEv2ysvXxVYE7gXuAxYEXgS+F7F/hOAjfK6q4HfSerTVsARcW9E9M9dRIOB+4Fr8urDgd2ALYHhwEzSHw75D+YXObbh+TWNaOOpzgQ2BrbI8X0HWJQTxTXAt4CVgZuBP0tavmLfPYEdgNHABsD+EfE00NQVNCgitm7rdWY/AP6aX+cI4PxWtjsfGAiskV/7fsBXKtZvRkpuQ4AzgEvU9qfO54FPAesAOwO3AN/Nr7cB+GbFtrcAawOrAA8AVwFExEX5/hn597VzxT57A58h/RwWNHvuA4AvSdpa0heBTalBK7tbqX0NZlNgUkQ8GxFvA9cCuzbbJoD35fsDgZfbO6gTjAGcDBwuaeVmyz8D/DciroyIBRFxDfAf0gdOk8sj4vG8/p287LKIeCYiZpE+fJ6JiFvzB8nvgDFNO0fEbyNiRt7/LKA38IEOxH4eMBtoao0cApwQEVMiYj5wCrB7biHsDtwYEXfmdScBi1o6aP72fwBwRES8FBELI+Kfeb8vADdFxN/yaz4T6EtKRIvjioiXI+J14M+kJLos3gFGAcMjYl5E3N1CrI2kpH58RMyOiOeBs0iJtMkLEXFxRCwErgCGkbrrWnN+RLwaES8BdwH3R8SDETEPuIGlf4eX5udt+nlvKGlgO6/rvIiYHBFvNV8REVOBQ3OcPwP2i4jZ7Ryvx1mGFswQSRMrbgdXHG5VYHLF4yl5WaVTgH0lTSF9qTq8vRidYIyIeAy4EWje7zqcJa2SJi+w9BtvMu/2asX9t1p4vLg4nbuSnszdK2+QvhkNqSZuSV8DtgL2iYimRDEKuCF3Xb1BajEtJH2YDq+MNw9smNHK4YeQaiXPtLBuqZ9Lfu7JLP1zmVpx/02WfYDCd0jfP/+Vu+QOaCXW5Vj6d9X897Q4noh4M99tK6aqfoeSGiX9RKlL8n/A8xUxtaWl902lP5Pqg0+1lFR7uqYifwcTzPSI2KTidlEHn3Zv0hfKEcCngSvVTt3VCcaafA84iKU/lF4mfWBXWg14qeJxLOsTKtVbvkPqThocEYOAWVTRoM/7/gDYNSL+V7FqMrBjRAyquPXJ38RfAUZWHKMfqZusJdOBeaQuvuaW+rnkrqaRLP1zqdbc/H+/imXvb7oTEVMj4qCIGA58Dfh5U92lWaxNLZ0mzX9PRdmH1JWyLenLwep5edPvsLX3R3vvmx+RvhwMk7T3e4yxW6plDYb0XhlZ8XgE737/HAhcD6mbmvQFrM0vEk4wBkBETAKuY0nf+g5Tp049ecCAARsfe+yx1+RC7BdIBcAbgVFjx47d8JxzzvkeqYYzAmCllVYadPbZZ58MPAQ8dPzxxx+37rrrrtbK0w4AFgDTgF6STmZJH2+rJI0kvdH3y3WNSr8EfiRpVN52ZUlNfcm/B3aS9LFcLzmVVv4GcqvkUuBsScPzN/XNJfXOz/0ZSdsoDTv+NjAf+Gd7sbfwPNNIf8j75uc4gIqkJmkPSU11opmkD+ZFzY6xMMf0I0kD8ms/CvhtR+PpCEk7kLoH1yDVfPoBP65Y3xv4CHCEpPu1ZHDH8sAvJT0k6WFJn2123E+Q6kf7AV8GzpfUvLvGaluDmQCsLWl0/tvYCxjXbJsXgW0AlAa19CH97bbKCcYqnQqskO9fOHTo0O2XW265bW666aZdGxoaZpJaGztFxHTgzNdee23qkUce+f2832kAM2bMeOOoo446lVRz2HrhwoXvPPPMM619kx4P/AV4mtSlM4/2u04gvcmHAr/XkpFkTcN+f0b6w/irpNnAfaQCNxHxOPAN0mCCV0gf2FPaeJ6jgUdJf3yvA6cDDRHxFLAvqbA+nVST2jkXR5fFQcAxpO66D7J0ovo/4H5Jc/LrOiIinm3hGIeTWkPPAnfn11j0yKsLSb+L8aQ63n9JP+8mB5K+aDwDfCjHBam19fWI2Ig0EOJXTTtIeh/wG+CwXPu6C7gEuKydQQk9i2rbgsn10cNIv8snSaPFHpd0qqRd8mbfBg6S9DBpkMv+EdFmS1TtrLeeaXNSQW/7/Pj4/P9pFds8TvpwmEz6fjSLd7c+DiaNaPpiUYFafUjaHDglIrbPj48HiIjTKrYZn7e5Nw+ymAqsXPmhJGk0KSmt2sJoMmvFciuvGSvtdnqH9nn113v8OyI2KSikFrkFYy2pZkTJw8Dn8v3Pkrq7mtcz9mLJ8GHrXqp5jyzeJiePWeT3iKTNcqvzUeAQJ5eOq3ENphCFJRilk8AqT5Y6WtIpNTr2KZJeyn24/5H0i/ZGM1jNHU1qnTyY/3+JNFqryTDgw6Qmt9lSIuL+PD3M/wHHq51zn2xpyziKrNMV+aE8H/icpKqGnC6Dc3If7vqkD7Itq91Rnp6iPdWMKHmZ1IIZw5JzUN6oWL8n6XyJd7DuqJr3yOJt8t/cQJoNC4+IJ4E5pBqNdUQJJrssMsEsAC4Cjmy+Qml6jNuVpqK4TdJqefnlks5TmmbkWUm7V/E8y5NGM8zMx7hD0ib5/hAtmUJkf0njJN0O3CZpq7zt73Mr6CoXERebQDozezTp59vSiJIhLHn/HM+7C8p74+6x7qyaUUfjSKPAIJ3kentERN6nF0Ae8bYuS86fsWrUuMhflKK/yV8IPCLpjGbLzweuiIgrlIZlnkea3gNS18rHSG+6caShpS05UtK+pLH/t0TEQ1XEMxbYICJeV5oafAxp1M7LwD3AR1ky0gVYPJ9SOuNVvTZWn8H0BDtuvw3nnPHDZxsbG7nsN1fz4zPOfez7Jx3LxAce4s83jefzu+3Ej089kYjgrnvu5RvfOo633377JIBRq43k7ttvZLW1N7q9pw0iGbNeayOyu5exYzdm1qxZTJky+dmIYKWVhjBs2LDHhg0bTr9+/Rg0aBAbbTSG559/jj59+nytX79+jB69BhtvvEmMGrU6r746lX79+tG3b1+GDRvOoEGDpm28cafWn+vmgQf+PT0ims+a0WFl+D5c2CgySXMior+kU0ndJG8B/SPiFEnTgWER8Y7SeQSvRMQQpam9/xYRV+VjzI6IAS0c+xRgTkScmff/PXBNRFwr6Q7g6IiYmLvnJkbE6pL2B7aMiK/kY2xFmlLkU/nxL4B7IqLVcwca+q0SvT+wZ01+PtY9zZxwQb1DsC6u73J6z6O5ll9lrRi6x1ntb1hhys9365ajyM4ljYdfob0Ns/kV9wWgNGPvQ5Le1UrJc0H9BfhEXrSAJa+reeFwbrPHlc+1EF8fx8zKoofXYADIk/1dT0oyTf5J6rOFdI7EXe0c44SI2CgX9ZeS6yYfZcmcUc+TZsCF1O9rZtbtlKEG01lDe89i6TlrDge+onQ9iC+xbFNxH5lbNI+RJsVrujbBmcChkh6kykkTzczKpKPJpV4Jxmfyd4BrMNYe12CsPbWowfQeunYM2+ucDu3zwnk7d3oNxjUHM7MSKsMoMicYM7My6vr5xQnGzKyM3IIxM7PakxOMmZkVQEAJ8osTjJlZ+dRv6HFHOMGYmZVQCfKLE4yZWekIGhq6foZxgjEzKxnhBGNmZgVxF5mZmRXCRX4zM6s9uQVjZmYFSOfBdP0M4wRjZlY6Pg/GzMwKUoL84gRjZlZGbsGYmVntuchvZmZFcJHfzMwKU4L84gRjZlZGbsGYmVkhSpBfnGDMzErHV7Q0M7Mi+IqWZmZWEJ/Jb2ZmBSlBfnGCMTMrI7dgzMys9nwmv5mZFcFn8puZWWGcYMzMrBAlyC9OMGZmZeQWjJmZ1Z6L/GZmVgSV5ETLhnoHYGZmHSd17Nb+8bSDpKckTZJ0XCvb7CnpCUmPS7q6vWO6BWNmVkKNDbVrwUhqBC4EPgVMASZIGhcRT1RsszZwPPDRiJgpaZX2jusWjJlZySjPptyRWzs2BSZFxLMR8TZwLbBrs20OAi6MiJkAEfFaewd1gjEzK6EGdezWjlWByRWPp+RlldYB1pF0j6T7JO3Q3kHdRWZmVkLLUOQfImlixeOLIuKiDuzfC1gb2AoYAdwp6cMR8UZbO5iZWckswyCy6RGxSSvrXgJGVjwekZdVmgLcHxHvAM9JepqUcCa09oTuIjMzKxmRhyp34F87JgBrSxotaXlgL2Bcs23+H6n1gqQhpC6zZ9s6aKstGEnva2vHiPhfexGbmVkxajiIjIhYIOkwYDzQCFwaEY9LOhWYGBHj8rrtJD0BLASOiYgZbR23rS6yx4GApVJf0+MAVlvmV2NmZsuuupFhHRIRNwM3N1t2csX9AI7Kt6q0mmAiYmRr68zMrL5KcCJ/dTUYSXtJ+m6+P0LSxsWGZWZmrRHQIHXoVg/tJhhJFwCfBL6UF70J/LLIoMzMrG21niqmCNUMU94iIsZKehAgIl7PowzMzKxOyjDZZTUJ5h1JDaTCPpJWAhYVGpWZmbWqnq2SjqgmwVwI/AFYWdL3gT2B7xcalZmZtaledZWOaDfBRMRvJP0b2DYv2iMiHis2LDMza0vXTy/VTxXTCLxD6ibz2f9mZnVWhhpMNaPITgCuAYaT5qe5WtLxRQdmZmYtS8OUazqbciGqacHsB4yJiDcBJP0IeBA4rcjAzMysFQWcyV+EahLMK82265WXmZlZnZQgv7Q52eU5pJrL68Djksbnx9vRxvTMZmZWvLK3YJpGij0O3FSx/L7iwjEzs/Y01WC6urYmu7ykMwMxM7Pqlb0FA4CkNYEfAesDfZqWR8Q6BcZlZmZt6PrppbpzWi4HLiO9nh2B64HrCozJzMzaIHWT2ZSBfhExHiAinomIE0mJxszM6qS7zKY8P092+YykQ4CXgAHFhmVmZm3pFjUY4EhgBeCbpFrMQOCAIoMyM7PWCdFYgmFk1Ux2eX++O5slFx0zM7N6Kft0/ZJuIF8DpiUR8blCIurC+q24IhvsvWe9w7Au7E+PvlTvEKyHKHsX2QWdFoWZmXVIGaa1b+tEy9s6MxAzM6uOKH8LxszMuqgS1PidYMzMyqhbJRhJvSNifpHBmJlZ+9LJk10/w1RzRctNJT0K/Dc/3lDS+YVHZmZmrSrDFS2rGYhwHrATMAMgIh4GPllkUGZm1rbuMlVMQ0S80Kw5trCgeMzMrB3pejBdv4usmgQzWdKmQEhqBA4Hni42LDMza0upz4OpcCipm2w14FXg1rzMzMzqpAQNmKrmInsN2KsTYjEzsyqojtd46Yhqrmh5MS3MSRYRBxcSkZmZtasE+aWqLrJbK+73AT4LTC4mHDMzq0a3ONEyIpa6PLKkK4G7C4vIzMza1J1GkTU3Ghha60DMzKx6JcgvVdVgZrKkBtMAvA4cV2RQZmbWhjqend8RbSYYpbMrNwSarqK0KCJavQiZmZl1DtH1M0yb5+rkZHJzRCzMNycXM7M6SzWY7jEX2UOSxhQeiZmZVa0MCabVLjJJvSJiATAGmCDpGWAuKXlGRIztpBjNzKyZMkzX31YN5l/AWGCXTorFzMyq0NRF1tW1lWAEEBHPdFIsZmZWjTpOwd8RbSWYlSUd1drKiDi7gHjMzKwKZTjRsq0ifyPQHxjQys3MzOqgiFFkknaQ9JSkSZJaPddR0uclhaRN2jtmWy2YVyLi1PbDMjOzziUaa9iCydf6uhD4FDCFNLBrXEQ80Wy7AcARwP3VHLetFkzXb3+ZmfVAouaXTN4UmBQRz0bE28C1wK4tbPcD4HRgXjVxtpVgtqnmAGZm1sk62D2Wu8iGSJpYcau85MqqLD1L/pS8bMlTSmOBkRFxU7VhttpFFhGvV3sQMzPrXMtQ5J8eEe3WTVoiqQE4G9i/I/sty2zKZmZWR01dZDX0EjCy4vEIlsxBCWlg14eAO/IJnu8HxknaJSImtnZQJxgzsxKq8TDlCcDakkaTEstewD5NKyNiFjCk6bGkO4Cj20ouUN1cZGZm1sXUssifpwU7DBgPPAlcHxGPSzpV0jLP5uIWjJlZyYjatw4i4mbg5mbLTm5l262qOaYTjJlZ2aj8k12amVkX1fXTixOMmVnppKliun6KcYIxMyuhrp9enGDMzEqpBA0YJxgzs/KRi/xmZlZ7RQxTLoITjJlZCbkFY2Zmhej66cUJxsysfHyipZmZFcE1GDMzK4xbMGZmVoiun16cYMzMSqkEDRgnGDOzskk1mK6fYZxgzMxKyC0YMzMrgJBbMGZmVgS3YMzMrOYkaCxBhnGCMTMroRLkFycYM7Mycg3GzMxqLl0yud5RtM8JxsyshNyCMTOzQrgGY2ZmhXALxszMas41GDMzK4jP5DczsyLINRgzMytICfKLE4y1bLPRg/nWNmvSKPHnR6Zy5f2T37XN1h8YwoEfHUUAk16byyk3/geAu47+OM9MmwvAq7Pnc+wfH+/M0K2TPHTP37nizO+xaOFCtv7s3uz6lcOWWv+331/JX6+/nIaGRvr0W4GDTjydEWusw2svT+bbn9+K4aPWBGDtD4/lqyf8pB4vobRSDabrpxgnGHuXBsHR267FEdc/ymuz53PJfmO4a9IMnp/x5uJtRgzuw34fWY1DrnqY2fMXMLjfcovXzV+wiP2veKAeoVsnWbRwIZeefiIn/PxqVho6jO/u+xk23nI7RqyxzuJtPrrDbnxq9y8BMPEff+XKs77P8RdeBcDQEatz+rV/rUvs3UXXTy/QUO8ArOtZf9gAprzxFi/PmseCRcGtT07j42uttNQ2u2wwjD88+DKz5y8AYOab79QjVKuTSY89xPtHrM7QEaPotdzybLH9rky8Y+mE0a//gMX357/1ZjmKBmWiDt7qwC0Ye5eV+/fm1dnzFz+eNns+6w8fsNQ2q63YF4Bf7rMhDQ3iknte4P7nZgKwfK8GLtlvDAsXBb+9bzJ3TprRecFbp3h92ius9P5hix+vuMr7mfTYg+/abvx1l3PTVRez4J23OelX1y1ePu2lFzlu7+3pu0J/9vz6d1hv7GadEnd34lFkNSRpIfAoKRcvBA6LiH/W6NgbAcMj4uZaHK8naGwQIwf35RvXPsIqA3rz87035EuXTWTO/IV87pf3M33O2wwf2Ifz99qAZ6bP5aU35tU7ZKuD7b+wP9t/YX/uvuUGbvj1eXz91HMZPGQVLrj5XwwYNJhnn3iEM799IGf+7valWjzWvjI0CMvURfZWRGwUERsCxwOndWRnSY1trN4I+PR7Ca47mTZnPkMH9F78eOUBvZk2++2ltnlt9nzunjSDhYuCV2bNY/LMNxk5OLVqps9J2748ax4PvPgG66zSv/OCt06x4srDmDH1lcWPX39tKiuuMqzV7bfYflcm3DEegOWW782AQYMBWGP9DRg6YhSvvPhssQF3QyXoIStVgqn0PmAmgKStJN3YtELSBZL2z/efl3S6pAeAPSTdkR//S9LTkj4uaXngVOALkh6S9IU6vJ4u5clXZjNicF+GDexDrwax7Xorc3ezbq47/zuDMasNAmBg316MHNyPl96Yx4DevViuUYuXbzBiIM9VDA6w7mHND27I1MnP8dpLL7Lgnbf55/g/sfGWn1pqm8qk8eBdtzFs5GgA/jdzBosWLgTg1SkvMPXF5xi66mqdF3x3UYIMU5ouMqCvpIeAPsAwYOsq95sREWMBJB0C9IqITSV9GvheRGwr6WRgk4g4rPnOkg4GDs4P59x77JZPvedXUgJHTdxz4Fmnnz6ysbGRqy+7cPrVxx039Zxzzhk+YcKEuVdfffWs+yQ+eNFFIy7f7RMrAgtOOvrwV8ZffPHMbbfddoWLL7xwVEQgibNP/e5r15x77vR6v57Ocu+x9Y6gUw385s5bjMz3px+zxzZTgeHAXGAWMJL0ZbARmAe8uNfYEfOAQcCqQOTby1/95IdndXbwdTTqvR4g5Yyu30emiKh3DFWRNCci+uf7mwO/Bj4EbAkcHRE75XUXABMj4nJJzwNbRsQLed0dwAkRcY+kocA9EbFWbvG0mGCsbZImRsQm9Y7Dui6/R2pv/Q3GxJXj/tGhfTYZPfDfnf17KFMLZrGIuFfSEGBlYAFLd/X1abb53GaPm4ZHLaSkr9/MrOu3X0pag5G0LqnZPQN4AVhfUm9Jg4BtluGQswEPYTGz8nANpqaaajCQflxfjoiFwGRJ1wOPAc8B7x6M376/A8fl458WEde1t4MtdlG9A7Auz++RmivHbMqlqcGYmVmy/gZj4+obO1aDGTPqfa7BmJlZ2+p5bktHlLIGY2bW49W4BiNpB0lPSZok6bgW1h8l6QlJj0i6TVK7w62dYMzMSkgd/NfmsdJMJxcCOwLrA3tLWr/ZZg+STufYAPg9cEZ7MTrBmFmnkuTPnRpoUMdu7dgUmBQRz0bE28C1wK6VG0TE3yOiaVqO+4AR7cbY8Zdl1nHS0lPzNX9sPUM+lWDzfP9jktarc0jl1NHusfTXNkTSxIrbwRVHXBWovKrglLysNQcCt7QXpov8VjhJijxcUdLHgOmkIeXz29zRuqNVgC0lHU86UXqr+oZTXsswTHl6LUaRSdoX2IQ0i0qbnGCscBXJ5WvAt0gntv5e0o0R8URdg7PO9gywEmkuwXMj4i1I3WYRsaiukZWIqPl0/S+R5o5rMiIvW/p5pW2BE0hTcLX7BdFdZFaYym4wSbsB20TEesBXSW/m3dxF0v1Vvg/yydFnAAcAy0s6TlKviFiUp3+yKtV4ENkEYG1Jo/MM83sB45Z6PmkM8Ctgl4h4rZoY3YKxQjTrFhsNbAZsJqlvRDwi6Qrgy8AXJV0ZET1iluqeqOJ9cDCpi+yliLhM0uvA54DDJM0EVpf0k2q+GRs1PREmIhZIOgwYT5qG69KIeFzSqaTJg8cBPwX6A7/L3xlejIhd2jquE4wVouJD5VDS/HAnAaOB8yQdERETJfUCdifVZKwbk7QrcARwLnCApA0i4khJbwNfINVidndyqV6tp4rJV/S9udmykyvub9vRYzrBWGEkbUNKIJ+LiFn529ChwNmSvh0R90l60B8q3U+zFuwupCvGHhoRd0q6AfiTpLMj4ijgDkkrRsTr9Yy5bMowDtM1GCuEpL7ADsAHgXXy4v+QTubqDfw4L3v73XtbmTVLLh8hdY9+BBgjqXdETCedY7GdpHMBnFw6rgSTKbsFY7WXLzt9J+lS1A3A/pLeiojHJD0NnEa64uHirjTrPiqSy/bA8RGxlaQnSTW3JyXdERHTJW2JL5Ox7NyCsR5qM+A2oB9wOqnGcpCkjSJiUUQ8HRGv1jVCK5SkfYBjSC1WIuK3wPXAUaSWy3IRMSMinq9flOXVdMnkWk0VUxQnGKsZSb0Bcr/6H0gjUkT6kHkH2CcPgbRuLA/eeIg0qGOLpuURcTFwE+kscL8P3gulGkxHbvXgBGM1IWkn4CRJKwFExEmkBPNHIEjnPvw0z3Nk3ZSkrUgn4r0IfAbYSdLXm9ZHxPnAVyKi+aXMrYPKUINxgrFlIumTks6UtHtuuTxN+rb6NUkr5s0uAgYB15CmqZhWp3CtIC3MKdcAjCKNFnwR+CzpPJdvN20QEW90XoTdWAkyjBOMdVgu3p5PKtSfAOwQEU8DBwEfA74h6f2kGVqvI31j9TQg3VBFQf/j+fHtwGXAGsA3gSeAL5Kmfx9crzi7n45WYOqTYTyKzDpE0hakD5D9IuJWSbNJ3SBvAY8C+wPnAGeSks2OETG5teNZOf1HZggAAAeASURBVOWu0EURMVNSf9KXir0j4usRcVeuw5wLrAicAmzh7tHa8nkw1q3k7pANgLuAWXkKmK+Tppb4MvAT4P3AwcCRwEci4sk6hWsFkfRp0lTtv5L0g4iYQxp6vpykc/N5MH8H7id1kfZxcqmtZZutv/M5wVjVcnfIlcDdpJFAtwEXRMQBpK6yWcDmETE3IqZFxNT6RWtFkLQD8F3gR6STZUfnIccPA2eR5qq6Ic87ti7wY59EWZASZBgnGKta/mY6F7iUdPnUfwNP5+XPA2+SPlSsG8qDN24GzoqIP5GGGm8D/EzShcBTpPNcniMN+Pi6z3Mpjmsw1q1EROTrdsyVdBWwHGko6sJc1N8O2KeuQVphIuJ1STsDP5T0LKkVcxFwCfA74OqI2Bs4UtLy7hYrVhlqME4w1qrKOaXy48oWb9+IuCDPlnw4ac6xnSPiP50dp3WeiLhJ0kJSC/a7EfETWDyx6Z8krZy7R51cClaC/OIuMmtZswkL++d+9kX5wlBbAI9KGkWqyfwB+JSvTtkzRMRfgO2Br0galBfvAfQF5tUtsJ6kJGfyuwVj79IsuRxNGm7cW9IBEfEKqcVyYES8kHe5ok6hWp1ExN8kfQu4W9LPSVdAPDgiZtc5tB6k67dhnGDsXSqSy9bATsAhpFFj90oaC+yT6zGq3N56loi4RVIjaTqgMRHxeL1j6imEazBWYnlOqcOA23Jd5ZicUP5FuvrgFHBy6eki4kZJgyLizXrH0tOUIL+4BmNJC3NKPQdMA9aTtCFARBwN/AX4S/7maoaTS324BmOl0KzmsjOwAHiDVGs5F9hDEhHxcEQcJmmViFhYx5DNerx3fyfsetyCscXytOrfJxX1LwW+RZryZRCwn6QP5U09K7JZnZXgRH63YHoySasBM/KJk6sAewJfjIgnJZ1JOlP/ZdIJdccCU8F1F7N6q2e3V0e4BdNDSRoKfBs4VFL/iHiNdGnjtwEiYiapBfPhPDT5mIiYXreAzWwpZZgqxgmm55oGTACGk06YEzAJuDZPtQ7pwlEjckF/QX3CNLMWlaCPzF1kPYyktYGGiHgqzyc2C9gROCgijpP0C+BOSY8Am5G6zFzQN+tiStBD5gTTk+SLRD0FTJf0fWAhabLCgcBakr4WEYdK2gzoA5weEc/VL2Iza00ZajBOMD1IRMyQtC1wK6l7dEPSJY3nkGovH85dZZdFxPz6RWpmbatfXaUjnGB6mIi4XdL2wHmkBDMU2Jo0l9SmwAeAawAnGLMuylPFWJeVJyo8GniMdFnjKySNI13fpV9EzKpvhGbWHTjB9FD5uh6LgPskbR4RM+odk5lVzy0Y69LybLjLA7dK2jgiFtU7JjOrjmsw1uVFxJ8k3ebkYlYiJTmT3wnGiIg59Y7BzKpXz/nFOsIJxsysjEqQYZxgzMxKyDUYMzMrRBlqMJ7s0kpN0kJJD0l6TNLvJPV7D8faStKN+f4uko5rY9tB+fo5HX2OU/I5SFUtb7bN5ZJ278BzrS7psY7GaOVQgrkunWCs9N6KiI0i4kOk6W4OqVyppMPv84gYFxE/aWOTQUCHE4xZzZQgwzjBWHdyF2nSztUlPSXpN6TZCkZK2k7SvZIeyC2d/gCSdpD0H0kPAJ9rOpCk/SVdkO8PlXSDpIfzbQvgJ8CaufX007zdMZImSHokTybadKwTJD0t6W7SVDxtknRQPs7Dkv7QrFW2raSJ+Xg75e0bJf204rm/9l5/kNb1leF6MK7BWLeQr2GzI/CXvGht4MsRcZ+kIcCJwLb56p3HAkdJOgO4mDQX2yTSxJ8tOQ/4R0R8Nl8bpz9wHPChiNgoP/92+Tk3JX1fHCfpE8Bc0jxvG5H+3h4gXSm0LX+MiIvzcX8IHAicn9etnp9jTeDvktYC9gNmRcT/SeoN3CPpr4CvPNpNPfjAv8f3W15DOrhbp18w0AnGyq6vpIfy/buAS0gXUXshIu7Lyz8CrE/64AVYHrgXWBd4LiL+CyDpt8DBLTzH1qQPcfK1cWZJGtxsm+3y7cH8uD8p4QwAboiIN/NzjKviNX0oJ5ZB+TjjK9Zdn0+K/a+kZ/Nr2A7YoKI+MzA/99NVPJeVUETsUO8YquEEY2X3VlMroklOInMrFwF/i4i9m2231H7vkYDTIuJXzZ7jW8twrMuB3SLiYUn7A1tVrGveKon83IdHRGUiQtLqy/DcZjXjGoz1BPcBH83dSUhaQdI6wH+A1SWtmbfbu5X9bwMOzfs2ShoIzCa1TpqMBw6oqO2sKmkV4E5gN0l9JQ0Adq4i3gHAK5KWA77YbN0ekhpyzGuQLiA3Hjg0b4+kdSStUMXzmBXKLRjr9iJiWm4JXJNrFAAnRsTTkg4GbpL0JqmLbUALhzgCuEjSgaSrgB4aEfdKuicPA74lIo6RtB5wb25BzQH2jYgHJF0HPAy8BkyoIuSTgPuBafn/ypheBP4FvA84JCLmSfo1qTbzQL5g3DRgt+p+OmbFUYTrgGZmVnvuIjMzs0I4wZiZWSGcYMzMrBBOMGZmVggnGDMzK4QTjJmZFcIJxszMCuEEY2Zmhfj/MHLJ8Kj4FNwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, \n",
    "                      classes=['Non-Burn','Burnt'], \n",
    "                      normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question:  \n",
    "### Please interpret the Confusion Matrix above.  (5 pts)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The normalized confusion matrix shows that the K-Nearest Neighbors (KNN) classifier performs well in identifying non-burnt areas, correctly classifying 97% of them, with only 3% misclassified as burnt. However, it struggles with detecting burnt areas, correctly identifying only 35%, while misclassifying 65% as non-burnt. This high false negative rate suggests that the model is biased towards predicting non-burnt areas, possibly due to class imbalance or feature limitations. To improve burnt area detection, techniques such as class balancing (e.g., SMOTE), adjusting decision thresholds, or trying alternative models like Random Forest or boosting methods could be beneficial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
